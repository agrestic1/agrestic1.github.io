[ { "title": "JTL WaWi", "url": "/posts/JTL-Wawi/", "categories": "JTL", "tags": "documentation, jtl, wawi, mssql, docker, synology", "date": "2022-07-21 00:00:00 +0200", "snippet": "JTL WaWiInstallationMSSQL 2017 Server @ SynologyAuf der Synology einen Ordner /volume1/docker/mssql/data anlegenDann Docker Container starten mit:version: \"3.4\"services: mssql: container_name: ...", "content": "JTL WaWiInstallationMSSQL 2017 Server @ SynologyAuf der Synology einen Ordner /volume1/docker/mssql/data anlegenDann Docker Container starten mit:version: \"3.4\"services: mssql: container_name: mssql image: mcr.microsoft.com/mssql/server:2017-latest restart: unless-stopped network_mode: bridge ports: - 1433:1433 environment: # - TZ=Europe/Berlin - SA_PASSWORD=XXXXXXXXXXXXX - ACCEPT_EULA=Y - MSSQL_PID=Express volumes: - /etc/localtime:/etc/localtime:ro - /volume1/docker/mssql/data:/var/opt/mssqlAnschließend und während Einrichtung mit WaWi am besten den Log anschauen, der gibt gute Hinweise auf mögliche FehlerDatenbank einrichten in JTLDie IP-Adresse der Synology angeben:Passwort des ServerAdmin-Nutzers “sa” SA_PASSWORD eingeben:Erstellung bestätigen:Expertenmodus aktivieren und Pfad C:\\var\\opt\\mssql\\data am besten per Durchsuchen wählen, für Zieldaten und ProtokolldatenFalls der Pfad vergessen wurde oder falsch ist kommt folgender Fehler:Console des MSSQL-Container ergibt aufschluss auf den falschen Pfad:Erfolg:" }, { "title": "WireHole", "url": "/posts/wirehole/", "categories": "documentation", "tags": "documentation, homelab, raspberry, wireguard, pihole, docker", "date": "2022-07-01 00:00:00 +0200", "snippet": "PiHole und WireguardQuelle: https://notes.iopush.net/blog/2020/wireguard-and-pi-hole-in-docker/Wir setzen einen Wireguard server auf. Im selben Docker Nezwerk befindet sich auch ein PiHole Containe...", "content": "PiHole und WireguardQuelle: https://notes.iopush.net/blog/2020/wireguard-and-pi-hole-in-docker/Wir setzen einen Wireguard server auf. Im selben Docker Nezwerk befindet sich auch ein PiHole Container, den wir als DNS-Server für die clienten definieren.Portainer stack mit Inhalt:version: \"3.5\"services: wireguard: image: linuxserver/wireguard depends_on: - pihole dns: - 172.29.0.2 # We specify the IPs manually cap_add: - NET_ADMIN - SYS_MODULE sysctls: - net.ipv4.conf.all.src_valid_mark=1 restart: unless-stopped volumes: - /etc/localtime:/etc/localtime:ro - /home/agrestic/wireguard:/config - /lib/modules:/lib/modules ports: - 51820:51820/udp environment: # - TZ=Europe/Berlin - SERVERURL=217.160.241.201 - SERVERPORT=51820 - PEERS=MSI,Surface,Lineage,FritzHalt,Guest # For each user a conf-File will be created - PEERDNS=172.29.0.2 # DNS: Ip of pihole labels: - \"com.centurylinklabs.watchtower.enable=true\" # Automatically update with Wireguard networks: network-pihole: ipv4_address: 172.29.0.3 pihole: image: pihole/pihole:latest volumes: - /etc/localtime:/etc/localtime:ro # TZ - /home/agrestic/pihole/etc-pihole/:/etc/pihole - /home/agrestic/pihole/etc-dnsmasq.d/:/etc/dnsmasq.d environment: # TZ: \"Europe/Berlin\" PROXY_LOCATION: pihole VIRTUAL_HOST: pi.hole VIRTUAL_PORT: 80 PIHOLE_DNS_: 208.67.222.222;208.67.220.220 restart: unless-stopped labels: - \"com.centurylinklabs.watchtower.enable=true\" # Automatically update with Wireguard ports: - \"53:53/tcp\" - \"53:53/udp\" # - \"67:67/udp\" # Only for DHCP, not used here - \"8081:80/tcp\" networks: network-pihole: ipv4_address: 172.29.0.2 # Piholes IP# Create the bridge-network and configure the subnet so we can specify the containers IPs manuallynetworks: network-pihole: name: \"dns-pihole\" driver: bridge ipam: driver: default config: - subnet: 172.29.0.0/16 gateway: 172.29.0.1Wireguard ConfigsConfigs runterladen (leider keine Rechte via SFTP):In Portainer:Containers &gt; wirehole_wireguard_1 &gt; Console root @ /bin/bashapt-get updateapt-get install -y vimvi /config/peer_MSI/peer_MSI.confvi /config/peer_Surface/peer_Surface.confvi /config/peer_Lineage/peer_Lineage.confvi /config/peer_FritzHalt/FritzHalt.confvi /config/peer_Guest/peer_Guest.confTo exit vim type: ESC : qPihole WebpasswordIn Portainer:Containers &gt; wirehole-pihole-1 &gt; Console root @ /bin/bashpihole -a -p" }, { "title": "Git-Fu", "url": "/posts/git/", "categories": "documentation", "tags": "documentation, github, website, gitlab, git", "date": "2022-06-24 00:00:00 +0200", "snippet": "Git-fuConfiguration:git config --global user.name \"Your name here\"git config --global user.email \"your_email@example.com\"I also do:git config --global color.ui truegit config --global core.editor e...", "content": "Git-fuConfiguration:git config --global user.name \"Your name here\"git config --global user.email \"your_email@example.com\"I also do:git config --global color.ui truegit config --global core.editor emacsThe first of these will enable colored output in the terminal; the second tells git that you want to use emacs.Look to see if you have files ~/.ssh/id_rsa and ~/.ssh/id_rsa.pub.If not, create such public/private keys: Open a terminal/shell and type:ssh-keygen -t rsa -C \"your_email@example.com\"Copy your public key (the contents of the newly-created id_rsa.pub file) into your clipboard.Paste your ssh public key into your github account settings.Go to your github Account SettingsClick “SSH Keys” on the left.Click “Add SSH Key” on the right.Add a label (like “My laptop”) and paste the public key into the big text box.In a terminal/shell, type the following to test it:ssh -T git@github.comIf it says something like the following, it worked:Hi username! You have successfully authenticated, but Github doesnot provide shell access.Use:git clone git@github.com:agrestic1/repoinstead of https://github.com/agrestic1/repoTo change the remote from http to ssh:git remote set-url origin git@github.com:agrestic1/repogit remote -vRepo Tokengit remote set-url origin https://agrestic1:TOKEN@github.com/agrestic1/repoUpdate your forkSzenario: You have forked a repository and did some changes. In the meantime also the original developer did some updates in his repository. You want to takeover these.Here we use a rebase, so our commits are then added to the new (updated) base.Quelle: https://stackoverflow.com/questions/7244321/how-do-i-update-or-sync-a-forked-repository-on-githubAdd the remote, call it “upstream”:git remote add upstream https://github.com/whoever/whatever.gitFetch all the branches of that remote into remote-tracking branchesgit fetch upstreamMake sure that you’re on your main branch:git checkout mainRewrite your main branch so that any commits of yours thataren’t already in upstream/main are replayed on top of thatother branch:git rebase upstream/mainIf you don’t want to rewrite the history of your master branch, (for example because other people may have cloned it) then you should replace the last command with git merge upstream/main. However, for making further pull requests that are as clean as possible, it’s probably better to rebase.If you’ve rebased your branch onto upstream/main you may need to force the push in order to push it to your own forked repository on GitHub. You’d do that with:git push -f origin mainYou only need to use the -f the first time after you’ve rebased.Git –assume-unchangedQuelle https://thisbailiwick.com/git-assume-unchanged/When installing apps locally some files have data which is unique to your install path or domain. For example I installed our app at EasyRx locally and the yaml setting for the domain used for cookies was tracked by git. I changed the value in my local install but then it showed up as a change in git which I definitely don’t want to commit.There is a temporary option.git update-index --assume-unchanged /path/to/file.ymlSetting --assume-unchanged to the file will effectively hide those changes.However, be aware, if you git add the specific file it will add it to the files staged for commit. If you just do a blanket git commit -a it won’t add the file. Of course you need to remember that it’s set that way!Let’s go over a quick example of using the command. Changes have been made to a few files in my working directory:$ git status# On branch master## Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)##\tmodified: README.textile#\tmodified: Rakefile#\tmodified: TODO#no changes added to commit (use \"git add\" and/or \"git commit -a\")If I ran git commit -a from here, all of the files would be added into the new commit. However, I want to temporarily ignore the changes in one of the files:$ git update-index --assume-unchanged README.textile $ git status# On branch master## Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)##\tmodified: Rakefile#\tmodified: TODO#no changes added to commit (use \"git add\" and/or \"git commit -a\")So if we commit the work now then turn the flag off, we can see that Git didn’t lose the original changes to the README. From there, you could now add them into a new commit, or revert back to the latest copy.$ git update-index --no-assume-unchanged README.textile$ git status# On branch master# Your branch is ahead of 'origin/master' by 4 commits.## Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)##\tmodified: README.textile#no changes added to commit (use \"git add\" and/or \"git commit -a\")Clone a single branchgit clone -b &lt;branchname&gt; --single-branch &lt;remote-repo-url&gt; &lt;foldername&gt;Then, if the repo was updated, to update your local copy dogit pullSpecial case: The gh-pages branch is generated by an github automation. This does a “forced update”, so it does not commit changes, insead it deletes the old branch and creates a new one with every build. Therefore git pull with it’s default merge setting won’t work. To pull new changes we have to rebase with:git pull --rebaseor set default pull setting to rebasegit config pull.rebase trueAnd in future we can just:git pull.gitignoreThe various files in your project directory that you’re not tracking in git should be indicated in a .gitignore file.You don’t have to have a .gitignore file, but if you don’t, those files will show up every time you type git status.Each subdirectory can have its own .gitignore file, too.Also, you can have a global such in your home directory; I use ~/.gitignore_global, which contains:*~.*~folder/folder/**/*.jsonYou have to tell git about the global .gitignore file:git config --global core.excludesfile ~/.gitignore_global" }, { "title": "Traefik loadbalancer with crowdsec Open Source & Collaborative Security", "url": "/posts/traefik/", "categories": "traefik", "tags": "homelab, dns, traefik, portainer, ssl, self-hosted, docker, loadbalancer, synology, crowdsec", "date": "2022-06-07 11:00:00 +0200", "snippet": "We’re going to use SSL for everything. No more self-sign certs. No more http. No more hosting things on odd ports. We’re going all in with SSL for our external services. We going to set up a r...", "content": "We’re going to use SSL for everything. No more self-sign certs. No more http. No more hosting things on odd ports. We’re going all in with SSL for our external services. We going to set up a reverse proxy using Traefik, Portainer, and use that to get certificates from Let’s Encrypt.QuellenTechno Tim traefik YoutubeTechno Tim traefik dokuThe digital life traefik youtubeThe digital life traefik dokuTechno Tim crowdsec YoutubeTechno Tim crowdsec dokuPihole im HostnetDocker SetupSee this post on how to install docker and docker-composeTraefikSSH into SynologyCreate the folder structure and necessary files. acme.json will store the SSL certificatescd /volume1/docker/mkdir -p traefik/data &amp;&amp; cd traefik/datatouch acme.jsonchmod 600 acme.jsontouch traefik.ymlvi traefik.ymltraefik.yml Contains the static configuration for traefik. Changese here need a restart of the traefik containerglobal: checkNewVersion: true sendAnonymousUsage: false # true by default# Log information; necessary for crowdseclog: level: \"INFO\" # DEBUG, INFO, WARNING, ERROR, CRITICAL filePath: \"/var/log/traefik/traefik.log\"# format: common # common, json, logfmt# Accesslog; necessary for crowdsecaccessLog: filePath: \"/var/log/traefik/access.log\" # format: common # common, json, logfmt# (Optional) Enable API and Dashboardapi: dashboard: true # true by default insecure: true # Don't do this in production!# Entry Points configurationentryPoints: web: address: :80 # Apply crowdsec-bouncer middleware to everything also docker services (crowdsec-bouncer middleware defined in dynamic.yml) http: middlewares: - crowdsec-bouncer@file # (Optional) Redirect to HTTPS, we don't do that here, but individually # http: # redirections: # entryPoint: # to: websecure # scheme: https websecure: address: :443 # Apply crowdsec-bouncer middleware http: middlewares: - crowdsec-bouncer@file# Configure your CertificateResolvers herecertificatesResolvers: staging: acme: email: rettichmann@live.de storage: /etc/traefik/acme.json caServer: \"https://acme-staging-v02.api.letsencrypt.org/directory\" httpChallenge: entryPoint: web production: acme: email: rettichmann@live.de storage: /etc/traefik/acme.json caServer: \"https://acme-v02.api.letsencrypt.org/directory\" httpChallenge: entryPoint: web cloudflare: acme: email: rettichmann@live.de storage: /etc/traefik/acme.json dnsChallenge: provider: cloudflare delayBeforeCheck: 0 resolvers: - 1.1.1.1:53 - 1.0.0.1:53serversTransport: insecureSkipVerify: true # Accept serlf signed certs from e.g. DSMproviders: docker: exposedByDefault: false # Default is true, if false containers need label \"traefik.enable=true\" to be exposed file: # watch for dynamic configuration changes directory: /etc/traefik watch: trueEnviroment variablesFor traefikvi /volume1/docker/portainer/data/compose/traefik.envtraefik.env# Necessary for cloudflare SSL certificate# Needs to go to /volume1/docker/portainer/data/compose, so that portainer can see it# referenced in compose with /data/compose/traefik.envCF_API_EMAIL=rettichmann@live.deCF_DNS_API_TOKEN=XXXXXXXXXXXXXXXXXXXTraefik Routes Configcd datatouch dynamic.ymlvi dynamic.ymldynamic.yml Contains the dynamic configuration for traefik. Changese here don’t need a restart of the traefik containerhttp:# ------ Routers -------- routers: dsm-insec: entryPoints: - web rule: \"Host(`dsm.onehumanwasted.de`) || Host(`nasty.onehumanwasted.de`)\" middlewares: - https-redirect # Leitet auf port 443 um, erzwingt also SSL für den externen traffik #service: service-dsm #SSL auch für internen trafic (mit DSM's self-signed certificate, daher muss serversTransport: insecureSkipVerify: true sein) service: service-dsm-insec # Funktioniert nicht, wenn in DSM ein HTTPS redirect eingestellt ist, denn dann wird auf https://nasty.onehumanwasted.de:2087/ weitergeleitet und Port 2087 ist extern nicht offen #tls: # certResolver: production dsm: entryPoints: - websecure rule: \"Host(`dsm.onehumanwasted.de`) || Host(`nasty.onehumanwasted.de`)\" service: service-dsm-insec # Kommunikation nach proxy ohne SSL, spart recourcen. In DSM darf HTTPS redirect nicht eingestellt sein tls: certResolver: cloudflare # Nextcloud, falls traefik nicht auf dem selben Endgeraet laeuft und damit nicht ueber docker labels konfigurierbar nextcloud-insec: entryPoints: - web rule: \"Host(`nextcloud.onehumanwasted.de`)\" middlewares: - https-redirect # Leitet auf port 443 um, erzwingt also SSL für den externen traffik - default-headers service: service-nextcloud tls: certResolver: cloudflare nextcloud: entryPoints: - websecure rule: \"Host(`nextcloud.onehumanwasted.de`)\" middlewares: - default-headers service: service-nextcloud tls: certResolver: cloudflare# ------ Services -------- services: service-dsm: loadBalancer: passHostHeader: true servers: - url: \"https://192.168.178.75:2087\" service-dsm-insec: # Nicht noetig fuer Synology Letsencrypt Zertifikat Erneuerung loadBalancer: passHostHeader: true servers: - url: \"http://192.168.178.75:5000\" service-nextcloud: #Nextcloud @ Synology loadBalancer: passHostHeader: true servers: - url: \"http://192.168.178.75:8082\"# ------ Middlewares -------- middlewares:# Declaring the user list# test-auth:# basicAuth:# users:# - \"Martin:XXXXXXXXXXXXXXX\" https-redirect: redirectscheme: scheme: https crowdsec-bouncer: forwardauth: address: http://bouncer-traefik:8080/api/v1/forwardAuth trustForwardHeader: true default-headers: headers: frameDeny: true browserXssFilter: true contentTypeNosniff: true forceSTSHeader: true stsIncludeSubdomains: true stsPreload: true stsSeconds: 15552000 customFrameOptionsValue: SAMEORIGIN customRequestHeaders: X-Forwarded-Proto: httpsCreate traefik networkHint: This needs to be executed after setting up Synology, even before installing portainer. It can be a sheduled task to run once as root with the following content.docker network create traefik_defaultCrowdseccd /volume1/docker/mkdir -p crowdsec/datacd crowdsecmkdir config &amp;&amp; cd configtouch acquis.yamlvi acquis.yamlacquis.yaml Tells crowdsec where the logs are and of what kind they are (labeled as traefik)filenames: - /var/log/traefik/*labels: type: traefikEnviroment variablesFor crowdsecvi /volume1/docker/portainer/data/compose/crowdsec.envcrowdsec.env# Needs to go to /volume1/docker/portainer/data/compose, so that portainer can see it# referenced in compose with /data/compose/crowdsec.envCROWDSEC_BOUNCER_API_KEY=XXXXXXXXXXDocker composecd /volume1/docker/traefik/touch docker-compose.ymlvi docker-compose.ymldocker-compose.ymlversion: '3'services: traefik: image: \"traefik:latest\" container_name: \"traefik\" ports: - \"80:80\" - \"443:443\" # (Optional) Expose Dashboard - \"8080:8080\" # Don't do this in production! volumes: - /etc/localtime:/etc/localtime:ro - /volume1/docker/traefik/data:/etc/traefik - /var/run/docker.sock:/var/run/docker.sock:ro - /volume1/docker/traefik/logs:/var/log/traefik # For crowdsec # environment: # - CF_API_EMAIL= xxx # API Token for the zone # - CF_DNS_API_TOKEN= xxx # -&gt; /volume1/docker/portainer/data/compose/traefik.env env_file: - /data/compose/traefik.env # Needs to be in /volume1/docker/portainer/data/compose, so that portainer can see it labels: ## Traefik # - \"traefik.enable=true\" # Muss an bleiben, sonst funktioniert middlewares.https-redirect@docker nicht # Http (Cloudlfare HTTPS redirect only works for main domain) - \"traefik.http.routers.traefik_insec.entrypoints=web\" - \"traefik.http.routers.traefik_insec.rule=Host(`traefik.onehumanwasted.de`)\" # HTTPS redirection - \"traefik.http.middlewares.traefik-https-redirect.redirectscheme.scheme=https\" # Create a middleware named traefik-https-redirect - \"traefik.http.routers.traefik_insec.middlewares=traefik-https-redirect\" # Apply the middleware named `traefik-https-redirect` to the router named `traefik_insec` # HTTPS - \"traefik.http.routers.traefik.entrypoints=websecure\" - \"traefik.http.routers.traefik.rule=Host(`traefik.onehumanwasted.de`)\" - \"traefik.http.routers.traefik.tls=true\" - \"traefik.http.routers.traefik.tls.certresolver=production\" # Authentication - \"traefik.http.middlewares.traefik-auth.digestauth.users=Martin:traefik:XXXXXXXXXXXX\" # Create a middleware - \"traefik.http.routers.traefik.middlewares=traefik-auth\" # Apply the middleware - \"traefik.http.routers.traefik.service=api@internal\" ## Watchtower - \"com.centurylinklabs.watchtower.enable=true\" #extra_hosts: # - host.docker.internal:172.17.0.1 # Damit auch pihole im Hostnet gefunden wird networks: - \"traefik_default\" restart: unless-stopped crowdsec: image: crowdsecurity/crowdsec:latest container_name: crowdsec environment: GID: \"${GID-1000}\" COLLECTIONS: \"crowdsecurity/linux crowdsecurity/traefik\" depends_on: #uncomment if running traefik in the same compose file - 'traefik' volumes: # - ./config/acquis.yaml:/etc/crowdsec/acquis.yaml - /volume1/docker/crowdsec/acquis.yaml:/etc/crowdsec/acquis.yaml # - crowdsec-db:/var/lib/crowdsec/data/ - /volume1/docker/crowdsec/data:/var/lib/crowdsec/data/ - crowdsec-config:/etc/crowdsec/ #- /volume1/docker/crowdsec/config:/etc/crowdsec/ # for some reason this does not work, needs to be a docker volume # - traefik_traefik-logs:/var/log/traefik/:ro - /volume1/docker/traefik/logs:/var/log/traefik/:ro networks: - traefik_default restart: unless-stopped labels: - \"com.centurylinklabs.watchtower.enable=true\" bouncer-traefik: image: docker.io/fbonalair/traefik-crowdsec-bouncer:latest container_name: bouncer-traefik environment: # Get api key with \"docker exec crowdsec cscli bouncers add bouncer-traefik\" and save it to crowdsec.env # CROWDSEC_BOUNCER_API_KEY: some-api-key # is now in crowdsec.env CROWDSEC_AGENT_HOST: crowdsec:8080 env_file: - /data/compose/crowdsec.env # Needs to be in /volume1/docker/portainer/data/compose, so that portainer can see it networks: - traefik_default # same network as traefik + crowdsec depends_on: # don't start until crowdsec is not started - crowdsec restart: unless-stopped labels: - \"com.centurylinklabs.watchtower.enable=true\"volumes: #crowdsec-db: crowdsec-config: #traefik_traefik-logs: # this will be the name of the volume from trarfic logs #external: true # remove if traefik is running on same stack networks: traefik_default: external: true # Join the existing network, created with portainer# Create network#networks:# network-traefik:# name: \"traefik_default\"# driver: bridge# ipam:# driver: defaultYour folder structure should look like the below, if you are following along with the example. But feel free to make it however you wish just keep in mind you’ll need to change the location in the corresponding files../traefik├── data│ ├── acme.json│ ├── dynamic.yml│ └── traefik.yml└── docker-compose.ymlSpin up the container…using docker-compose, better use a Portainer stack!docker-compose up -ddocker-compose up -d --force-recreateGenerate Auth Password, to protect the traefik dashboardOn another (any) Linux machine do:sudo apt updatesudo apt install apache2-utilsBasic authBasic auth uses non-encrypted base64 encoding. Therefore, Basic Authentication should generally only be used where transport layer security is provided such as https.echo $(htpasswd -nb &lt;USER&gt; &lt;PASSWORD&gt;) | sed -e s/\\\\$/\\\\$\\\\$/gNOTE: Replace &lt;USER&gt; with your username and &lt;PASSWORD&gt; with your password to be hashed.Paste the output in your docker-compose.yml in line (traefik.http.middlewares.traefik-auth.basicauth.users=&lt;USER&gt;:&lt;HASHED-PASSWORD&gt;)Digest authhtdigest -c pwdfile traefik &lt;USER&gt; &amp;&amp; cat pwdfileNOTE: Replace &lt;USER&gt; with your username and &lt;PASSWORD&gt; with your password to be hashed.Paste the output in your docker-compose.yml in line (traefik.http.middlewares.traefik-auth.digest.users=&lt;USER&gt;:traefik:&lt;HASHED-PASSWORD&gt;)Anleitung um traefik mit crowdsec zu konfigurieren (bereits in yml und docker-compose umgesetzt):cd ../traefikcd datavi traefik.ymlAdjustments for crowdsec in traefik.yml// check to be sure you have your middleware set for bothentryPoints: web: address: \":80\" # Apply crowdsec-bouncer middleware to everything also docker services (crowdsec-bouncer middleware defined in dynamic.yml) http: middlewares: - crowdsec-bouncer@file websecure: address: \":443\" # Apply crowdsec-bouncer middleware http: middlewares: - crowdsec-bouncer@file// at the end add the logging options:log: level: \"INFO\" filePath: \"/var/log/traefik/traefik.log\"accessLog: filePath: \"/var/log/traefik/access.log\"vi dynamic.ymldynamic.yml// in middlewares add crowdsec-bouncer crowdsec-bouncer: forwardauth: address: http://bouncer-traefik:8080/api/v1/forwardAuth trustForwardHeader: truecd ..mkdir logsvi docker-compose.ymldocker-compose.yml// add volume for logs volumes: - /volume1/docker/traefik/logs:/var/log/traefik # For crowdsec# Start crowdsec and restart traefik# see metrics, check if traefik logs are readdocker exec crowdsec cscli metrics# must look like this#Acquisition Metrics:#+----------------------------------+------------+--------------+----------------#| Source | Lines read | Lines parsed | Lines unparsed#+----------------------------------+------------+--------------+----------------#| file:/var/log/traefik/access.log | 58 | 58 | - #+----------------------------------+------------+--------------+---------------- # see bansdocker exec crowdsec cscli decisions list# manually install collections# no need to do that, since we've defined the enviroment variable COLLECTIONS: \"crowdsecurity/linux crowdsecurity/traefik\" in docker-compose.ymldocker exec crowdsec cscli collections install crowdsecurity/traefik# update hubsdocker exec crowdsec cscli hub update# upgrade hubsdocker exec crowdsec cscli hub upgrade# add bouncer# (save api key somewhere and add it to the crowdsec.env file)docker exec crowdsec cscli bouncers add bouncer-traefik# ban ipdocker exec crowdsec cscli decisions add --ip 192.168.0.101# see bansdocker exec crowdsec cscli decisions list# unban ipdocker exec crowdsec cscli decisions delete --ip 192.168.0.101Synology Drive / DSM:Neuen täglichen Task Sheduler @root um crowdsec täglich upzudaten:docker exec crowdsec cscli hub update &amp;&amp; docker exec crowdsec cscli hub upgradeAm handy muss dsm.onehumanwasted.de verwendet werden, da die Kommunikation dort über https läuft und traefik dann an den richtigen Port (2087) verweist.Am Computer muss Domain ohne Cloudflare Proxy z.b. nasty.onehumanwasted.de verwendet werden, da Cloudlfare Port 6690 und das Drive-Protokoll nicht kann.Traefik sollte auf der Domain auch lauschen (traefik horcht ja nur auf 80 443 und 8080) damit Certifikat-Erneuerung funktioniert." }, { "title": "Docker", "url": "/posts/docker/", "categories": "homelab", "tags": "homelab, docker, linux, wsl", "date": "2022-06-07 11:00:00 +0200", "snippet": "DockerInstallationInstall docker:First updatesudo apt update &amp;&amp; sudo apt upgradeA) docker.iodocker.io does it the Debian (or Ubuntu) way: Each external dependency is a separate package that...", "content": "DockerInstallationInstall docker:First updatesudo apt update &amp;&amp; sudo apt upgradeA) docker.iodocker.io does it the Debian (or Ubuntu) way: Each external dependency is a separate package that can and will be updated independently.sudo apt install docker.ioB) docker-cedocker-ce does it the Golang way: All dependencies are pulled into the source tree before the build and the whole thing forms one single package afterwards. So you always update docker with all its dependencies at once.Follow https://docs.docker.com/engine/install/ubuntu/Does not work on JETSON -&gt; use docker.ioC) Use Ansible (only for ubuntu)On another Linux machine:sudo apt updatesudo apt install ansible gitgit clone https://github.com/agrestic1/ansible/cd ansibleansible-playbook install-docker.yaml --limit ionos_lAdd your user to the docker groupsudo usermod -aG docker $USERCheatsheetCheck what containers are runningdocker psList all containers (incl stopped)docker ps -aqGet into it:docker exec -it pihole1 bashSometimes, when bash is not available, this always works:docker exec -it pihole1 /bin/shSet new password for piholesudo pihole1 -a -pexitStop the containerdocker stop pihole1Start the containerdocker start pihole1remove the containerdocker rm pihole1list imagesdocker image listrenove the imagedocker rmi pihole/pihole:latestlist the networksdocker network lsCreate an imagecreate a file called dockerfileFROM nginx:stable-alpineCOPY _site /usr/share/nginx/htmldocker build .With tagdocker build -t myimage .To ignore files create a .dockerignore file**/password.txtnode_modulescoveragenpm-debug.log.DS_Storeyarn-error.log.idea.vscode.yarn-cache.yarn-cache/Run the image (make it a container)docker run -d --name mycontainer -p 80:80 myimageRestore the content of a docker volumeLets create an ubuntu container and mount the docker volume and a backup folderdocker run -it -v docker_volume:/data -v ~/backup:/backup --name backup_container ubuntu bashand then copy the content of the docker volume to the backup foldercd datacp -r * ../backupexitCleanupdocker rm backup_container # Removes the containerdocker rmi ubuntu # Removes the ubuntu imagedocker volume rm docker_volume # Removes the backed up volumeWSLFrom https://www.youtube.com/watch?v=idW-an99TAM&amp;t=25sInstall Docker Desktop in windowshttps://docs.docker.com/desktop/windows/install/Enable WSL2 based engineEnable integration with WSL DistrosIn WSL, add your user to the docker groupsudo usermod -aG docker $USER" }, { "title": "HowTo create documentation site", "url": "/posts/docs/", "categories": "documentation", "tags": "docker, nginx, synology, documentation, github, website, jekyll, gitlab", "date": "2022-06-06 22:00:00 +0200", "snippet": "HowTo create documentation siteFrom: https://docs.technotim.live/posts/jekyll-docs-site/📺 Watch VideoInstall Dependenciessudo apt updatesudo apt install ruby-full build-essential zlib1g-dev gitTo a...", "content": "HowTo create documentation siteFrom: https://docs.technotim.live/posts/jekyll-docs-site/📺 Watch VideoInstall Dependenciessudo apt updatesudo apt install ruby-full build-essential zlib1g-dev gitTo avoid installing RubyGems packages as the root userecho '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrcecho 'export GEM_HOME=\"$HOME/gems\"' &gt;&gt; ~/.bashrcecho 'export PATH=\"$HOME/gems/bin:$PATH\"' &gt;&gt; ~/.bashrcsource ~/.bashrcInstall Jekyll bundlergem install jekyll bundlerCreating a site based on Chirpy StarterVisit https://github.com/cotes2020/jekyll-theme-chirpy#quick-startIf you want to use git pages, your repo must be public, and you need to name the repo XXXXX .github.ioAfter creating a site based on the template, clone your repogit clone git@&lt;YOUR-USER-NAME&gt;/&lt;YOUR-REPO-NAME&gt;.gitthen install your dependenciescd repo-namebundleAfter making changes to your site, commit and push then up to gitgit add .git commit -m \"made some changes\"git pushJekyll Commandsserving your sitebundle exec jekyll sBuilding your site in production modeJEKYLL_ENV=production bundle exec jekyll bThis will output the production site to _siteBuilding Site in CIThis site already works with GitHub actions, just push it up and check the actions Tab.,For GitLab you can see the pipeline I built for my own docs site hereHost the site locally - Building with DockerCreate a Dockerfile with the followingFROM nginx:stable-alpineCOPY _site /usr/share/nginx/htmlBuild site in production modeJEKYLL_ENV=production bundle exec jekyll bThen build your image:docker build -t docs .Or if you want to separate repo from site, just clone the repository page branch:git clone -b gh-pages --single-branch https://github.com/agrestic1/agrestic1.github.io.git agrestic1_siteCreate a dockerfilenano ~/dockerfilecontentFROM nginx:stable-alpineCOPY agrestic1_site /usr/share/nginx/htmlbuild and run a nginx webserver with that contentdocker build -t docs .docker run -d --name docs -p 80:80 docsPull new changes into the webserverThe gh-pages branch is generated by an github automation. This does a “forced update”, so it does not commit changes, insead it deletes the old branch and creates a new one with every build. Therefore git pull with it’s default merge setting won’t work. To pull new changes we have to rebase with:git pull --rebaseor set default pull setting to rebasegit config pull.rebase trueAnd in future we can just:git pullCreating a PostNaming ConventionsJekyll uses a naming convention for pages and postsCreate a file in _posts with the formatYEAR-MONTH-DAY-title.mdFor example:2022-05-23-homelab-docs.md2022-05-34-hardware-specs.mdLocal Linking of FilesImage from asset:... which is shown in the screenshot below:![A screenshot](/assets/screenshot.jpg)Linking to a file... you can [download the PDF](/assets/diagram.pdf) here.See more post formatting rules on the Jekyll siteMarkdown ExamplesIf you need some help with markdown, check out the markdown cheat sheetI have lots of examples in my documentation site repo.Just click on the Raw button to see the code behind the page.For more neat syntax for the Chirpy theme check their demo page on making posts https://chirpy.cotes.page/posts/write-a-new-post/" }, { "title": "Tdarr server and node configuration to convert Videos to h265", "url": "/posts/tdarr-server/", "categories": "homelab", "tags": "tdarr, docker, hevc, h265, nvidia", "date": "2022-04-16 10:00:00 +0200", "snippet": "From https://docs.technotim.live/posts/tadarr-server/Tdarr is a distributed transcoding system that runs on on Windows, Mac, Linux, Arm, Docker, and even Unraid. It uses a server with one or more ...", "content": "From https://docs.technotim.live/posts/tadarr-server/Tdarr is a distributed transcoding system that runs on on Windows, Mac, Linux, Arm, Docker, and even Unraid. It uses a server with one or more nodes to transcode videos into any format you like. Today, we’ll set up the Docker and Windows version of Tdarr using a GPU to regain up to 50% of your disk space back. I converted my video collection using Tdarr to h265.📺 Watch VideoHowtoHowTo:Ordner temp und media in den docker container mounten. In tdarr eine Library erstellen, auf lokalen ordner verweisen “/tdarr_convert”, Transcode cache “/temp” und GPU aktivieren.Docker Server + Nodedocker-compose.ymlversion: \"3.4\"services: tdarr: container_name: tdarr image: ghcr.io/haveagitgat/tdarr:latest restart: unless-stopped network_mode: bridge ports: - 8265:8265 # webUI port - 8266:8266 # server port - 8267:8267 # Internal node port environment: # - TZ=America/Chicago - PUID=1000 - PGID=1000 - UMASK_SET=002 - serverIP=0.0.0.0 - serverPort=8266 - webUIPort=8265 - internalNode=true - nodeID=MyInternalNode - nodeIP=0.0.0.0 - nodePort=8267 - NVIDIA_DRIVER_CAPABILITIES=all - NVIDIA_VISIBLE_DEVICES=all volumes: - /etc/localtime:/etc/localtime:ro - /volume1/docker/tdarr/data/server:/app/server - /volume1/docker/tdarr/data/configs:/app/configs - /volume1/docker/tdarr/data/logs:/app/logs # - /volumeUSB1/usbshare/Filme/:/media # - /volumeUSB1/usbshare/Bilder/:/bilder - /volumeUSB1/usbshare/tdarr_convert/:/tdarr_convert - /volumeUSB1/usbshare/temp:/temp # - /volume1/homes/Martin/tdarr_convert/:/tdarr_convert # funktioniert nicht, Medien auf volume1 werden in tdarr im Browser der library nicht angezeigt, obwohl im container vorhanden (docker exec -it) # - /volume1/homes/Martin/temp:/temp devices: - /dev/dri # For Intel grafic card and QSV # deploy: # resources: # reservations: # devices: # - capabilities: # - gpuWindows NodeAm Rechner müssen Laufwerke mit diesem Ordner ebenfalls gemountet sein und in Tdarr_Node_Config.json für den Computer richtig translatet, siehe unten.Tdarr_Node_Config.json{ \"nodeID\": \"MSI\", \"serverIP\": \"100.125.34.70\", \"serverPort\": \"8266\", \"handbrakePath\": \"\", \"ffmpegPath\": \"\", \"mkvpropeditPath\": \"\", \"pathTranslators\": [ { \"server\": \"/tdarr_convert\", \"node\": \"Y:/tdarr_convert/\" }, { \"server\": \"/temp\", \"node\": \"Y:/temp\" } ], \"platform_arch\": \"win32_x64_docker_false\", \"logLevel\": \"INFO\", \"nodeIP\": \"100.111.213.103\", \"nodePort\": \"8267\"}" } ]
